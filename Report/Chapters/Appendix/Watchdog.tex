\chapter{Watchdog Application}
\label{appendix:WD}
This appendix describes the development of a watchdog application in SCJ. This was done prior to the development of the CSP, and is the initial version made before CSP based edition. The contents of this chapter are therefore not directly related to CSP.


\section{Introduction}
The watchdog is based on the following problem setting. In a distributed system multiple modules communicate to accomplish a task as seen in Figure \ref{img:Problem.pdf}. In case of failure in one or more modules, the system should take appropriate actions as other modules may be dependent on the failed module(s). The watchdog has the single goal of detecting such failures of any module and take appropriate action.

\img{Problem.pdf}{0.5}{Five separate modules working on a common task in a distributed setting.}

\section{Environment Model and Setup}
For the watchdog we create a small hardware setup to model a scenario in which a module periodically provides sensor readings. As other modules would be dependent on these readings, the watchdog must detect any failures in the sensor module. In this case the watchdog only has to monitor a single module, however, the actual implementation should allow multiple devices to be monitored.

Figure \ref{img:setup.pdf} shows the setup of this small model. An \textit{Altera DE2-70} FPGA configured to run JOP (running at 60 MHz) will host the watchdog application implemented in Safety-Critical Java (SCJ). Connected to the Altera, is a Lego NXT UltraSonic sensor that provides distance-to-objects measurements. The connection between the watchdog and sensor happens on an \iic bus. Each module on the bus is uniquely identified using a 7-bit address, thus $127$ modules can be connected simultaneously. For analysis purposes, the watchdog will be limited to a maximum of 10 connected modules.

\img{setup.pdf}{0.7}{Altera DE2-70 and Lego NXT UltraSonic sensor used in hardware setup.}

\section{Tasks and Temporal Requirements}
The watchdog will be implemented as a compliance level~1 SCJ application as this allows us to explore the SCJ specification in greater depth compared to restricting ourselves to level~0 features. Later we will try to implement a variant running as a level~0 application under a cyclic executive scheduler.

The tasks required for the watchdog depends on the communication flow. The watchdog can be designed to be the master such that it initiates and monitors each module, or each module can act as masters that regularly contacts and resets a timer in the watchdog. While the \iic is a multi-master protocol, only one master and slave may communicate on the bus at a time.
A multi-master approach in this distributed setting with modules contacting the watchdog, could lead to starvation of one or more modules due to repeated bus congestion, leading (incorrectly) to the watchdog assuming a module failure.

Instead we design the system around the watchdog acting as the sole master on the bus, in which failure of each module on the bus is checked one by one. We designate three different tasks, (1) for handling \iic communication with each slave module (\textit{Pinger}), (2) that checks the status of each module based on the responses received in the first task and the final task (\textit{Checker}), (3) a \textit{Recovery} handler that handles a module failure. The \textit{Recovery} handler was originally designed to be an aperiodic task (which is often the case for error handling related tasks, according to Burns and Wellings~\cite{alan2001real}) released by a software interrupt generated by the second \textit{Checker} task when a module is considered failed. This has since been changed to a periodic task in order to simplify analysis. Table \ref{tab:taskslol} shows the tasks along with related scheduling assignments.
\begin{table}
\centering
\begin{tabular}{ | l | l | c | c | c |}
\hline
Task & Type & Period & Deadline & Priority  \\ \hline
\textit{Pinger} & Periodic & 500 & 200 & 5  \\ \hline
\textit{Checker} & Periodic & 500 & 100 & 10 \\ \hline
\textit{Recovery} & Periodic & 500 & 50 &  15 \\
\hline
\end{tabular}
 \caption{Task Set}
 \label{tab:taskslol}
\end{table}

The periods of the tasks are assigned such that the watchdog begins its monitor cycle every half second. We assign priorities according to deadline monotonic priority ordering. We argue that despite deadline enforcement and detection not being available in SCJ, it is suitable to consider deadlines due to the precedence relationship between the tasks - not only must both the \textit{Pinger} and \textit{Checker} tasks be done executing when either is to be released at a new period, the \textit{Pinger} task must run before the \textit{Checker} which we in turn want to run before the \textit{Recovery} handler. Ensuring this linear execution also lets us avoid having to handle synchronisation and thereby analysis of possible blocking time. The implementation must therefore be done to ensure these deadlines hold (these deadline requirements will then be verified as part of the response-time analysis of the implementation). The deadline of the \textit{Pinger} is set on the pessimistic assumption that each module communication times out 10 ms after the watchdog initiates communication with it (in which case it is considered failed). In the worst case where the maximum of 10 modules times out, 100 ms will be spent on this alone. In order to correct the priorities and take the precedence relationship into account, we need the \textit{Checker} and \textit{Recovery} handlers to enforce these to run in a serial manner, despite all being assigned the same period. As in Burns~\cite{Burns94preemptivepriority-based} we do this by stretching the deadline of the \textit{Checker} and \textit{Recovery} handler tasks and relate their deadline to the start of the transaction with the \textit{Pinger}, and not their own period and create a new transformed task set as listed in Table \ref{tab:tasks2}. An alternative approach could be to provide the \textit{Checker} and \textit{Recovery} handlers with an initial offset, which would avoid creating a critical instant. Note that this transformed task set also includes initial estimated computation times, that the implementation must not exceed (based on a pessimistic assumption for each task).
	\begin{table}
    \centering
    \begin{tabular}{ | l | l | c | c | c | c |}
    \hline
    Task & Type & Period & Computation Time & Deadline & Priority  \\ \hline
    \textit{Pinger} & Periodic & 500 & 150 & 200 & 15  \\ \hline
    \textit{Checker} & Periodic & 500 & 20 & 300 & 10 \\ \hline
    \textit{Recovery} & Periodic & 500 & 40 & 350 & 5 \\
    \hline
    \end{tabular}
     \caption{Transformed Task Set}
     \label{tab:tasks2}
    \end{table}

It can be discussed whether the \textit{Pinger} and \textit{Checker} task should be a single task, considering the \textit{Pinger} will actually detect whether a module is failed in case it does not respond after the 10 ms timeout. With the \iic protocol, where one cannot directly send an asynchronous message to a slave and then let another task check for response, the \textit{Pinger} must also receive the raw response from a module. This module alone would therefore be able to detect a failure and generate the software interrupt for the \textit{Recovery} handler. One could use a special \iic micro controller, dedicated to the communication which the tasks could communicate through, but this is beyond the scope of this. In our case the \textit{Checker} task will simply have to look at the stored results from the \textit{Pinger}.

We made the division into two separate tasks for two reasons, (1) to create a design that would be suitable for use in a case where another communication channel is utilized (and where a ping may be sent asynchronously by the \textit{Pinger} and the actual response is checked in another task) and (2) for adhering to the \textit{Single Responsibility Principle (SRP)} where an object should have only a single responsibility for maintainability purposes.

\section{Schedulability Analysis of Task Model}
We here provide an initial response-time analysis to ensure the specified tasks are schedulable in relation to the parameters specified in our model. For this we ignore any possible scheduling and context-switch overhead that would occur. We ignore this as a result of this system being comprised of only three tasks, and where context-switches only happens when each task has finished its release. A benefit of the transformed task set, is that it manages the precedence relationship between the tasks. For the implementation, no synchronisation is thereby required, and as a result, no blocking time is necessary to be included in the analysis.

As a result we calculate the response-time of tasks using Equation \ref{eq:rta} from Burns and Wellings.
\begin{equation}
\label{eq:rta}
     R_{i} = C_{i} + \sum\limits_{j\in hp(i)} \ceil{\frac{R_{i}}{T_{j}}} \cdot C_{j}
\end{equation}

The following shows the response-times for the modelled tasks in the transformed task set (Table \ref{tab:tasks2}):
\begin{equation}
\label{eq:pingerrta1}
     R_{pinger} = C_{pinger} = 150 
\end{equation}

\begin{eqnarray}
    w_{checker}^0 &=& C_{checker} = 20 \nonumber \\ 
    w_{checker}^1 &=& 20 + \ceil{\frac{20}{500}} \cdot 150 = 170 \nonumber \\ 
    w_{checker}^2 &=& 20 + \ceil{\frac{170}{500}} \cdot 150 = 170 \nonumber \\
    R_{checker} &=& 170
\end{eqnarray}

\begin{eqnarray}
    w_{recovery}^0 &=& C_{recovery} = 40 \nonumber \\ 
    w_{recovery}^1 &=& 40 + \ceil{\frac{40}{500}} \cdot 20 + \ceil{\frac{40}{500}} \cdot 150 = 210 \nonumber \\ 
    w_{recovery}^2 &=& 40 + \ceil{\frac{210}{500}} \cdot 20 + \ceil{\frac{210}{500}} \cdot 150 = 210 \nonumber \\
    R_{recovery} &=& 210
\end{eqnarray}

We can here see that the tasks of our model are indeed (very much) schedulable under FPS\footnote{The original task set defined in Table \ref{tab:taskslol} is, however, not!} as the response time for each task is below its deadline. That is: \\\\
$R_{pinger} < D_{pinger}$, $R_{checker} < D_{checker}$ and $R_{recovery} < D_{recovery}$

\section{Design and Implementation}
The implementation of the watchdog can be found on our GitHub repository~\cite{SW902e12:CSPinSCJ}. In addition to the implementation, additional time has been spent on optimizing the development and analysis process both for this project and long term for future SCJ development. Build and run scripts that we created can be found in Appendix \ref{cha:build_scripts} and a Python script for performing response-time analysis can be found in Secion \ref{cha:rta_calculator}.

In the following a brief description of the implementation is described on an abstract level (confined to abstract design class diagrams). The Java packages comprising the structure of the watchdog is illustrated in Figure \ref{img:UML.pdf}. 
\img{UML.pdf}{0.7}{UML for the packages in the project}

The \code{system} package contains the main method that starts the SCJ application using the designated safelet. Mission and safelet classes lies within the \code{sw901e12} package. The three periodic tasks are implemented as periodic event handlers in the \code{sw901e12.handlers} package.
The \code{sw901e12.comm} and the sub package modules contains everything that takes care of \iic communication and actual pinging of the modules once the system runs. We did a few things in these packages, as a result of the following considerations:
\begin{itemize}
    \item Running the watchdog in a simulator does not provide access to hardware registers used to control, read and write data on the \iic bus (or any modules to monitor)
    \item Different types of hardware setups exists (in our case it only runs on the Altera DE2-70 board as previously described, but it would be nice to allow for easy extensible code should it run elsewhere)
    \item Different types of modules are communicated with differently using \iic --- i.e. in order to determine if it responds, we may need to send different commands depending on the device.
\end{itemize}

In short, the communication should change based on which environment the watchdog is executed in and which modules are monitored. Figure \ref{img:UMLFactories.pdf} shows the contents of the \code{sw901e12.comm} package and the \code{sw901e12.comm.modules} sub package.

\img{UMLFactories.pdf}{0.7}{Abstract Factory pattern for handling different types of communication implementations and protocols.}

The first class hierarchy shows the use of the \textit{Abstract Factory} pattern. At run-time in the \textit{initialization} phase, for each module that is to be monitored, a \code{ModulePinger} object is created that knows how to communicate with that particular module. The \textit{Pinger} task can then simply invoke a ping method on the corresponding \code{ModulePinger} object for each monitored module. In the \textit{initialization} phase, the abstract factory creates a factory object depending on where the application runs. E.g. when the watchdog executes on the Altera board, an instance of \emph{BoardModulePingerFactory} is created. Subsequently this can be used to get \code{Pinger} objects for specific modules using an \iic address. In our setup the factory is used to create a \code{Pinger} object for the \iic bus address 0x01 which is the UltraSonic sensor. Because this sensor requires the use of what is known as a "repeated start" when communicating with it, a \code{TwoWayDirectionPinger} object is returned by the factory which knows how to handle this.
The \code{SimulatorModulePingerFactory} always returns \code{DummySimulatorModule} \code{Pinger} objects regardless of which \iic address a \code{Pinger} object is requested for. This dummy pinger simply performs a bit of sleep and then always returns a response. The benefit of having structured all communication like this, is that the remaining implementation of all event handlers etc. can simply ignore in which environment the system is executed.

For the \textit{Recovery} periodic event handler, it was considered that different recovery routines may be relevant in different situations. It should therefore be possible to easily extend or modify what recovery routine is executed. Instead of directly implementing the recovery routine in the designated recovery periodic event handler, recovery routines implements the \emph{IRecoveryRoutine} interface as illustrated in Figure \ref{img:UMLRecoveryInterface.pdf}. This routine is then encapsulated in a separate object, which the periodic \textit{Recovery} event handler may invoke an execute method on in case a module has failed to respond.

\img{UMLRecoveryInterface.pdf}{0.3}{Implementing recovery routines.}

\section{Implementation Under a Cyclic Executive} % (fold)
\label{sec:implementing_the_watchdog_as_a_cyclic_executive}
While the original implementation conforms to level~1 compliance of SCJ, the following describes an alternative implementation that conforms to level~0 (or is intended to be able to), that is, the watchdog is implemented as a cyclic executive.

Currently SCJ on JOP does not provide a cyclic executive implementation that follows the specification. Neither is the JOP specific cyclic executive implementation functional in its current state. We therefore implemented the cyclic executive version in a way that ensures the three tasks are both executed as if they were run by a specification complete cyclic executive scheduler and in the same environment, e.g. each handler should have its own private memory when released.

In order to change the current version (level~1) of the watchdog to a level~0 application, several changes needed to be done. The major cycle (schedule table) was defined as follows: The major cycle consists of one time-slot (frame) containing one minor cycle. There is only one minor cycle as each task must execute right after the completion of the previous. To capture this approach, a scheduling class, \code{CyclicSchedule}, was created, that allows one to instantiate frames containing tasks that must run in each frame. The tasks are changed to implement the \code{Runnable} interface instead of extending \code{PeriodicEventHandler} and the logic moved to the \code{run} method. Also a wrapper, \code{Task}, is created that holds the runnable type (the task logic) as well as auxiliary data. During mission initialisation, three tasks are instantiated and supplied with their respective runnable (\textit{Pinger}, \textit{Checker} or \textit{Recovery}). The tasks are then placed inside a newly created frame by using the \code{CyclicSchedule} class. A single periodic event handler is registered with the mission, that is responsible for running the contents of each frame. This event handler has a period of 500 ms. Upon invoking the run method of each task, a nested private scope is entered. The tasks were changed as a consequence of using this \code{enterPrivateMemory} as it expects a scope size and a \code{Runnable} type whose \code{run} method is executed behind the scenes. Because of this fact it was necessary to change the event handers to \code{Runnable}s.

When running the application, everything works as expected. The watchdog using this implementation can also be found at our GitHub repository~\cite{SW902e12:CSPinSCJ}.

% section implementing_the_watchdog_as_a_cyclic_executive (end)

\section{Determining WCET} % (fold)
\label{sec:determining_wcet}
To find the worst-case execution time (WCET) for the three tasks, the tasks are inspected and calculated individually. For the watchdog application, this calculation is done using either static analysis in which the target source code is analysed without the program running or measurement-based where the target code is executed (note that we do this for the original level~1 based implementation). For the \textit{Checker} and \textit{Recovery} handlers, static analysis will be performed using a WCET analysis tool (WCA) provided with the JOP project\footnote{This tool analyses the compiled java bytecode instructions while taking the cache into account. The output of running the tool is a report containing graphs, highlighted analysed code and WCET results in clock cycles.}. Compared to conducting run-time measurements, WCA is able to output an exact cycle count as each bytecode instruction in a SCJ compliant application running on JOP is cycle time accurate making this method preferable. On the other hand, the combination and simplicity of JOP and the FPGA board makes the run-time method acceptable due to there only being a single cache (method cache), a single processor (and thereby no parallelism) and no interleaving processes that can claim CPU time.

In the \textit{Checker}, to properly analyse the loop iterating over each module in order to check the response, a bound annotation is set to 10, thereby restricting the application to handle a maximum of 10 module devices. As the WCET for the \textit{Recovery} handler depends on the supplied recovery algorithm, a dummy recovery option is utilised which respectively toggles the LEDs on the Board with busy-wait loops in between for simulating work. These loops are bounded to 1000 iterations using the previously mentioned tool annotations. Running the tool on the two handlers yields to the following WCET results where the cache always misses:
\begin{itemize}
    \item $C_{checker} = 5832\ cycles \Rightarrow \frac{5832\ cycles}{60.000.000\ cycles/sec} \cdot 1000 = 0.0972\ ms$
    \item $C_{recovery} = 32337\ cycles \Rightarrow \frac{32337\ cycles}{60.000.000\ cycles/sec} \cdot 1000 = 0.53895\ ms$
\end{itemize}

Unfortunately the logic and implementation of the \textit{Pinger} prevents the same static analysis method due to temporal constraints. More specifically, the \textit{Pinger} invokes the \textit{ping} method of each module, which uses the \iic protocol to communicate with the slave module. After requesting a memory address to read from, a timeout mechanism disallows the \textit{Pinger} to continue to the next module as the response (if any) can be somewhat slow due to it being an I/O operation. The timeout is set to 10 ms which should more than enough time to determine whether or not the slave module is alive and talkative. Furthermore as the timeout mechanism is dependent on time, it is not possible to use WCA. Alternatively, this timeout mechanism could be implemented as a blocking operation for a full 10 ms, before checking for a module response, however, this would move the watchdog up to become a compliance level~2 SCJ application, which we want to avoid. To circumvent this issue, dynamic measurements are used through the use of a hardware timer. On the Altera board and in the \iic configuration of JOP, a hardware timer with a resolution down to 1 $\mu$s is available. To avoid polluting the watchdog with measuring code we used inheritance to make a derived WCET-version of the \textit{Pinger}. In its \code{handleAsyncEvent} method we surrounded the call to the handling code contained in the the super class with native reads of the hardware timer (start and stop). The start time is then subtracted from the end time as well as the total time is takes to perform two timer reads\footnote{These two timer reads are measured at run-time in advance and stored in a variable}. Downloading the watchdog application to the FPGA board and running the handler numerous times for about one minute gave the following maximum value, $100161\ \mu s $. As it is impossible to verify, no-matter how long you run the application, that the value indeed is the worst-case execution time, it is common to add another 20\% to the result in order to be on the 'safe side'. This yields the following WCET result:

\begin{itemize}
    \item $C_{pinger} = 100161\ \mu s \cdot 1.25 = 125201.25\ \mu s \Rightarrow \frac{125201.25\ \mu s}{1000\ \mu s /ms} = 125.20125\ ms$
\end{itemize}

Alternatively it should be mentioned that the \textit{Pinger} task could be measured using a hybrid of both approaches. To do this, we would place timers around the timeout method, \code{timeoutBasedWaitForModuleResponse}, and use WCA on the remaining code sections. The resulting WCET would then be an aggregation of the WCA and the timing measurements. 
% section determining_wcet (end)

\section{Response-Time Analysis} % (fold)
\label{sec:response_time_analysis_of_watchdog}
Using the measured WCET we here perform the final response-time analysis of the concrete implementation. As the WCET for all tasks are way below the specified computation times in our earlier model, it is trivial to verify the schedulability of the implementation. We will, however, provide the calculations below for good measure and proper verification.

\begin{equation}
\label{eq:pingerrta}
     R_{pinger} = C_{pinger} = 125,20125
\end{equation}

\begin{eqnarray}
    w_{checker}^0 &=& C_{checker} = 0,0972 \nonumber \\ 
    w_{checker}^1 &=& 0,0972 + \ceil{\frac{0,0972}{500}} \cdot 125,20125 = 125,29845 \nonumber \\ 
    w_{checker}^2 &=& 0,0972 + \ceil{\frac{125,29845}{500}} \cdot 125,20125 = 125,29845 \nonumber \\
    R_{checker} &=& 125,29845
\end{eqnarray}

\begin{eqnarray}
    w_{recovery}^0 &=& C_{recovery} = 0,53895 \nonumber \\ 
    w_{recovery}^1 &=& 0,53895 + \ceil{\frac{0,53895}{500}} \cdot 0,0972 + \ceil{\frac{0,53895}{500}} \cdot 125,20125 = 125,8374 \nonumber \\ 
    w_{recovery}^2 &=& 0,7226 + \ceil{\frac{126,02105}{500}} \cdot 0,0972 + \ceil{\frac{126,02105}{500}} \cdot 125,20125 = 125,8374 \nonumber \\
    R_{recovery} &=& 125,8374
\end{eqnarray}

Again, the fixed-point equations are solved and the provided response-time for each task does not exceed their deadlines, hence schedulability is ensured. In other words the following conditions hold: \\\\
$R_{pinger} < D_{pinger}$, $R_{checker} < D_{checker}$ and $R_{recovery} < D_{recovery}$

% chapter build_scripts (end)

\chapter{RTA Calculator} % (fold)
We created the following Python script to quickly determine whether or not a set of tasks is schedulable. In the \code{init\_tasks} function, the properties of the tasks must be stated and then each task object placed in the \code{tasks} list.
\label{cha:rta_calculator}
\lstinputlisting[language=Python]{Files/rta.py}
% chapter rta_calculator (end)
