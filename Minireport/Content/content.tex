\chapter{Requirements}
\section{Problem}
The Watchdog is based on the following problem setting. In a distributed system multiple modules communicate to accomplish a task as seen in Figure \ref{img:Problem.pdf}. In case of failure in one or more modules the system should take appropriate actions as other modules may be dependant on the failed module(s). The watchdog has the single goal of detecting such failures of any module and take appropriate action.
\img{Problem.pdf}{0.5}{Three seperate modules working on a common task in a distributed setting}

\section{Environment Model and Setup}
For the watchdog we set up a small hardware setup to model a scenario in which a module periodically provides sensor readings. As other modules would be dependant on these readings, the watchdog must detect any failures in the sensor module. In this case the watchdog only has to monitor a single monitor, however, the actual implementation should allow multiple devices to be monitored.

Figure \ref{img:setup.pdf} shows the setup of this small model. An Altera DE2-70 FPGA configured to run JOP will host the watchdog application implemented in Safety-Critical Java (SCJ). Connected to the Altera, is a Lego NXT UltrasSonic Sensor that provides distance to objects measures. The connection between the watchdog and sensor happens on an $\textit{I}^2\textit{C}$ bus. Each module on the bus is uniquely identified using a 7-bit address, thus $127$ modules can be connected simultaneously. For analysis purposes, the watchdog will be limited to a maximum of 10 connected modules.
\img{setup.pdf}{0.7}{Altera DE2-70 and Lego NXT UltraSonic Sensor used in hardware setup}

\section{Tasks and Temporal Requirements}
The tasks required for the watchdog depends on the communication flow. The watchdog can be designed to be the master that initiates and monitors each module, or each module can act as masters that regularly contacts and resets a timer in the watchdog. While the $\textit{I}^2\textit{C}$ is a multi-master protocol, only one master and slave may communicate on the bus at a time. A multi-master approach in this distributed setting with modules contacting the watchdog, could lead to starvation of one or more modules due to repeated bus congestion, leading (incorrectly) to the watchdog assuming a module failure.

Instead we design the system around the watchdog acting as the sole master on the bus, in which failure of each module on the bus checked one by one. We designate three diffeerent tasks, (1) for handling $\textit{I}^2\textit{C}$ communication with each slave module, (2) that checks status of each module based on the responses received in the first task and the final task (3) that handles a module failure. The recovery handler was originally designed to be an aperiodic task released by a software interrupt generated by the second checker task in case when a module is deemed failed. This has since been changed to a periodic to simplify analysis. Table \ref{tab:tasks} shows the tasks along with related scheduling assignments.
\begin{center}
	\begin{table}
    \begin{tabular}{ | l | l | c | c | c |}
    \hline
    Task & Type & Period & Deadline & Priority  \\ \hline
    \textit{Pinger} & Periodic & 500 & 200 & 5  \\ \hline
    \textit{Checker} & Periodic & 500 & 100 & 10 \\ \hline
    \textit{Recovery} & Periodic & 500 & 50 &  15 \\
    \hline
    \end{tabular}
    \label{tab:tasks}
     \caption{Task Set}
    \end{table}
\end{center}

The periods of the two periodic tasks are assigned such that the watchdog begins it monitor cycle every half second. We assign priorities according to deadline monotonic priority ordering. We argue that despite deadline enforcement and detection not being available in SCJ, it is suitable to consider deadlines due to the precedence relationship between the tasks - not only must both the pinger and checker tasks be done executing when either is to be released at a new period, the pinger task must run before the checker which we in turn want to run before the recovery handler. Ensuring this linear execution also lets us avoid having to handle syncronization and thereby analysis of possible blocking time. The implementation must therefore be done to ensure these deadlines hold (these deeadline requirements will then be verified as part of the WCET analysis as described in Chapter \ref{chapter:wcetrta}). The deadline of the pinger is set on the assumption that each module communication times out 10 ms after the watchdog initiates communication with it (in which case it is consider failed). In the worst case where the maximum of 10 modules times out, 100 ms will be spent on this alone. In order to correct the priorities and take the precedence relationship into account, we need the checker and failure handler to have an offset and enforce these to run in a serial manner, despite all having the same period. As in Burns\footnote{http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.25.9149} we do this by stretching the deadline of the checker and recovery handler tasks and relate their deadline to the start of the transaction with the pinger, and not their own period and create a new transformed task set as listed in Table \ref{tab:tasks2}. Note that this transformed task set also includes initial estimated computation times, that the implementation must not exceed (pessimistic assignment).
\begin{center}
	\begin{table}
    \begin{tabular}{ | l | l | c | c |c | c |}
    \hline
    Task & Type & Period & Computation Time & Deadline & Priority  \\ \hline
    \textit{Pinger} & Periodic & 500 & 150 & 200 & 15  \\ \hline
    \textit{Checker} & Periodic & 500 & 20 & 300 & 10 \\ \hline
    \textit{Recovery} & Periodic & 500 & 40 & 350 & 5 \\
    \hline
    \end{tabular}
    \label{tab:tasks2}
     \caption{Transformed Task Set}
    \end{table}
\end{center}

It can be discussed whether the pinger and checker task should be a single task, considering the pinger will actually detect whether a module is failed in case it does not respond after the 10ms timeout. With the $\textit{I}^2\textit{C}$ protocol, where one cannot directly send an asynchronous message to a slave and then let another task could check for response, the pinger must also receive the raw response from a module. This module alone would therefore be able to detect a failure and generate the software interrupt for the failure handler. One could use a special $\textit{I}^2\textit{C}$ microcontroller, dedicated to the communication which the tasks could communicate through, but this is beyond the scope of this. In our case the checker task will simply have to look at the stored results from the pinger.

We made the division into two seperate tasks for two reasons, (1) to create a design that would be suitable for use in a case where another communication channel is utilised (and where a ping may be sent asynchronously by the pinger and the actual response is checked in another task) and (2) for adhering to the \textit{Single Responsibility Principle (SRP)} where an object should have only a single responsibility for maintainability purposes.

\section{Schedulability Analysis of Task Model}
We here provide an initial response-time analysis to ensure the specified tasks are schedulable in relation to our parameters specified based upon our model. For this we ignore any possible scheduling and context-switch overhead that would occur. A benefit of the transformed task set, is that it manages the precedence relationship between the tasks. For the implementation, no synchronization is thereby required, and as a result, no blocking time is necessary to be included in the analysis.

As a result we calculate the response-time of tasks using Equation \ref{eq:rta} from Burns and Wellings.
\begin{equation}
\label{eq:rta}
     R_{i} = C_{i} + \sum\limits_{j\in hp(i)} \ceil{\frac{R_{i}}{T_{j}}}*C_{j}
\end{equation}

The following shows the response-times for the modelled tasks in the transformed task set (Table \ref{tab:tasks2}):
\begin{equation}
\label{eq:pingerrta}
     R_{pinger} = C_{pinger} = 150 
\end{equation}

\begin{eqnarray}
    w_{checker}^0 &=& C_{checker} = 20 \nonumber \\ 
    w_{checker}^1 &=& 20 + \ceil{\frac{20}{500}}*150 = 170 \nonumber \\ 
    w_{checker}^2 &=& 20 + \ceil{\frac{170}{500}}*150 = 170 \nonumber \\
    R_{checker} &=& 170
\end{eqnarray}

\begin{eqnarray}
    w_{recovery}^0 &=& C_{recovery} = 40 \nonumber \\ 
    w_{recovery}^1 &=& 40 + \ceil{\frac{40}{500}}*20 + \ceil{\frac{40}{500}}*150 = 210 \nonumber \\ 
    w_{recovery}^2 &=& 40 + \ceil{\frac{210}{500}}*20 + \ceil{\frac{210}{500}}*150 = 210 \nonumber \\
    R_{recovery} &=& 210
\end{eqnarray}

We can here see that the tasks of our model are indeed (very much) schedulable under FPS\footnote{The original task set defined in Table \ref{tab:tasks} is, however, not!}.

\chapter{Design and Implementation}
The implementation of the watchdog can be found on GitHub in the repository at \url{https://github.com/Todberg/SW9/tree/master/Code/Watchdog}. In addition to the implementation, additional time has been spent on optimizing the development and analysis process both for this project and long term for future SCJ development. Build and run scripts created are found in Appendix \ref{cha:build_scripts} and a small python script for performing response-time analysis is found in Appendix \ref{cha:rta_calculator}.

In the following a brief description of the implementation is described on an abstract level (confined to abstract design class diagrams). The Java packages comprising the structure of the watchdog is illustrated in Figure \ref{img:UML.pdf}. 
\img{UML.pdf}{0.7}{UML for the packages in the project}
The system package contains the main method that starts the SCJ application using the designated safelet. Mission and safelet classes lies within the sw901e12 package. The three periodic tasks are implemented as periodic event handlers in the sw901e12.handlers package.
The sw901e12.comm and the sub package modules contains everything that takes care of $\textit{I}^2\textit{C}$ communication and actual pinging of the modules once the system runs. We did a few things in these packages, as a result of the following considerations:
\begin{itemize}
    \item Running the watchdog in a simulator does not provide access to hardware registers used to control, read and write data on the $\textit{I}^2\textit{C}$ bus (or any modules to monitor)
    \item Different types of hardware setups exists (in our case it runs on the Altera DE2-70 board previously described only, but it would be nice to allow for easy extensible code should it run elsewhere)
    \item Different types of modules are communicated with differently using $\textit{I}^2\textit{C}$, that is, in order to determine if it responds, we may need to send different commands depending on the device.
\end{itemize}

In short, the communication should change based on which environment the watchdog is executed in and which modules are monitored. Figure \ref{img:UMLFactories.pdf} shows the contents of the sw901e12.comm package and the sw901e12.comm.handlers subpackage.
\img{UMLFactories.pdf}{0.7}{Abstract Factory pattern for handling different types of communication implementations and protocols}
The first class hierarchy shows the use of the Abstract Factory pattern. At run time in the \emph{initialization} phase, for each module that is to be monitored, a \emph{ModulePinger} object is created that knows how to communicate with that particular module. The pinger task can then simply invoke a ping method on the corresponding \emph{ModulePinger} object for each monitored module. In the initialization phase, the abstract factory creates a factory object depending on where the application runs. E.g. when the watchdog executes on the Altera board, an instance of \emph{BoardModulePingerFactory} is created. Subsequently this can be used to get pinger objects for specific using an $\textit{I}^2\textit{C}$ address. In our setup the factory is used to create a pinger object for the $\textit{I}^2\textit{C}$ bus address 0x1 which is the UltraSonic Sensor. Because this sensor requires the use of what is known as a "repeated start" when communicating with it, \emph{TwoWayDirectionPinger} object is returned by the factory which knows how to handle this.
The \emph{SimulatorModulePingerFactory} always returns \emph{DummySimulatorModule} pinger objects regardless of which $\textit{I}^2\textit{C}$ address a pinger object is requested for. This dummy pinger simply performs a bit of sleep and then always returns a response. The benefit of having structured all communication like this, is that the remaining implementation of all event handlers etc. can simply ignore in which environment the system is executed.

For the recovery periodic event handler, it was considered that different recovery routines may be relevant in different situations, it should therefore be possible to easily extend or modify what recovery routine is executed. Instead of directly implementing the recovery routine in the designated recovery periodic event handler, recovery routines implement the interface \emph{IRecoveryRoutine} as illustrated in Figure \ref{img:UMLRecoveryInterface.pdf}. This routine is then encapsulated in a seperate object, which the periodic event handler may invoke an execute method on in case a module is failed.
\img{UMLRecoveryInterface.pdf}{0.3}{Implementing recovery routines}

\chapter{WCET and Response-Time Analysis}
\label{chapter:wcetrta}
\section{Determining WCET} % (fold)
\label{sec:determining_wcet}


% section determining_wcet (end)

\section{Response-Time Analysis of Watchdog} % (fold)
\label{sec:response_time_analysis_of_watchdog}
Using the measured WCET we here perform the final response-time analysis of the concrete implementation. As the WCET for all tasks are way below the specified computation time in our earlier model, it is trivial to verify the schedulability of the implementation. We will, however, provide the calculations below for good measure and to verify this completely.
\begin{equation}
\label{eq:rta}
     R_{i} = C_{i} + \sum\limits_{j\in hp(i)} \ceil{\frac{R_{i}}{T_{j}}}*C_{j}
\end{equation}

The following shows the response-times for the modelled tasks in the transformed task set (Table \ref{tab:tasks2}):
\begin{equation}
\label{eq:pingerrta}
     R_{pinger} = C_{pinger} = 125,20125
\end{equation}

\begin{eqnarray}
    w_{checker}^0 &=& C_{checker} = 0,0972 \nonumber \\ 
    w_{checker}^1 &=& 0,0972 + \ceil{\frac{0,0972}{500}}*125,20125 = 125,29845 \nonumber \\ 
    w_{checker}^2 &=& 0,0972 + \ceil{\frac{125,29845}{500}}*125,20125 = 125,29845 \nonumber \\
    R_{checker} &=& 125,29845
\end{eqnarray}

\begin{eqnarray}
    w_{recovery}^0 &=& C_{recovery} = 0,53895 \nonumber \\ 
    w_{recovery}^1 &=& 0,53895 + \ceil{\frac{0,53895}{500}}*0,0972 + \ceil{\frac{0,53895}{500}}*125,20125 = 125,8374 \nonumber \\ 
    w_{recovery}^2 &=& 0,7226 + \ceil{\frac{126,02105}{500}}*0,0972 + \ceil{\frac{126,02105}{500}}*125,20125 = 125,8374 \nonumber \\
    R_{recovery} &=& 125,8374
\end{eqnarray}

Again, the fixed-point equations are solved and the provided response-time for each task does not exceed their deadlines, hence schedulability is ensured.

% section response_time_analysis_of_watchdog (end)

